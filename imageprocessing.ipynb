{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrYosJwpU5iit8z/QeJ5zr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rjahin/Prac_Image_Processing/blob/main/imageprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZgRGZDFQNhC",
        "outputId": "52eed92b-9f29-486a-e937-deb5d6a0e470"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark opencv-python numpy scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "metadata": {
        "id": "YiaEqGo1jOjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"ImageProcessingML\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "Lijp9Xani8fW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def extract_features(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, (64, 64))\n",
        "    return img.flatten()"
      ],
      "metadata": {
        "id": "8EFfI8FsQe-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def load_data(base_path):\n",
        "    data = []\n",
        "    labels = []\n",
        "    for label in os.listdir(base_path):\n",
        "        folder_path = os.path.join(base_path, label)\n",
        "        for file in os.listdir(folder_path):\n",
        "            file_path = os.path.join(folder_path, file)\n",
        "            try:\n",
        "                features = extract_features(file_path)\n",
        "                data.append((features.tolist(), label))\n",
        "            except:\n",
        "                pass\n",
        "    return data\n"
      ],
      "metadata": {
        "id": "hVRM3C_XaQ6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_data(\"/content/dataset\")"
      ],
      "metadata": {
        "id": "-1aK46wVinO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = spark.sparkContext\n",
        "rdd = sc.parallelize(data) #To process your data in parallel\n",
        "\n"
      ],
      "metadata": {
        "id": "DbR-Tk52iyia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.sql import Row\n",
        "\n",
        "df = rdd.map(lambda x: Row(features=Vectors.dense(x[0]), label=x[1])).toDF()\n"
      ],
      "metadata": {
        "id": "BBPeKVg6jqFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "indexer = StringIndexer(inputCol=\"label\", outputCol=\"label_index\")\n",
        "df = indexer.fit(df).transform(df)"
      ],
      "metadata": {
        "id": "D7BtpGe3kCTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = df.randomSplit([0.8, 0.2])"
      ],
      "metadata": {
        "id": "IfDFatIOkJDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label_index\")\n",
        "model = lr.fit(train_data)"
      ],
      "metadata": {
        "id": "ZSKmdFzjkLS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.transform(test_data)\n",
        "predictions.select(\"label\", \"label_index\", \"prediction\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "admZSPrXkUdq",
        "outputId": "03e66d2f-ebb1-4bef-85fb-5cbfee777d41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------+----------+\n",
            "|label|label_index|prediction|\n",
            "+-----+-----------+----------+\n",
            "|  dog|        1.0|       1.0|\n",
            "|  cat|        0.0|       1.0|\n",
            "+-----+-----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"label_index\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXZPTzkukhNt",
        "outputId": "758471ff-4d31-4174-bd18-d01272dbbb89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.50\n"
          ]
        }
      ]
    }
  ]
}